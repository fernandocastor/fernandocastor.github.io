---
layout: post
comments: true
title:  "Disorganized Notes about WWDC 2019, Day 1, 2019-06-03"
date:   2019-06-03 18:35:00
categories: swift
---

Every year, Apple promotes its Worldwide Developers Conference, which this year gathered 6000 atendees from more than 70 countries. Sice I am attending, I am using this blog to publish my completely disorganized and not-for-public-consumption notes. 

# Keynote

The main event of WWDC. Usually, lots of announcements, most of them not for developers. 

## tvOS

AppleTV+ was announced at the Apple event in March. A new TV series exclusive to this service caled *For All Manking* was introduced.

tvOS now has multiuser support, similarly to what Netflix already supports. tvOS supports music streaming based on Apple Music. It will be possible to also see the lyrics for the songs. 

AppleTV, together with the Apple Arcade, will now support XBox One and Playstation 4 controllers. Will that be by default or will it require specific SDKs?


## Apple Watch

More watch faces for Apple Watch. The watch will now be able to emit a sound or a haptic signal each hour. 

More Apple apps brought to the watch: Audiobooks, Voice Memos, and Calculator. The latter has a special "tip" calculation button.

Apple Watch will now support independent iPhone apps, without the need for an iPhone counterpart. 

New Streaming Audio API to stream audio independently. 

The App Store is now available at the Apple Watch, accessible by dictation, Siri. It is possible to directly install an app in the watch. 

New feature for watchOS 6: Activity trends. Captures historical data about physical activity, similarly to what is already available in apps such as Runkeeper. 

The presenter also talked about hearing health. There is a new app called Noise that monitors environmental noise and measures it so as to alert the user about excessive noise. Apple does not record the noise. 

Apple Watch now also has an app about menstrual cycle tracking. Supports monitoring of flow level, notifies about upcoming (expected) cycles. The app will also keep historical data. Cycle tracking will also be available for iOS. 

The Health app will present multiple pieces of information, employing ML to propose the ones that may be the most relevant to the user.


## iOS

iOS 13 will be released this year, in the fall. It includes multiple optimizations to run faster. Downloads will (hopefully) be 50% smaller and updates 60% smaller. Apps will launch faster. The main reason is that apps will be packaged differently. 

iOS will now support a Dark Mode. Also, it will finally support  swiping for typing. Apple Music will be able to play music with time-synchred lyrics. "Intelligent sharing": iOS will suggest people with whom the user customarily shares stuff. 

Reminders was rewritten from scratch. It will evaluate the reminders at write time to understand when the remider should be triggered. 

Maps now includes a lot more information. For the US, this will be available this year. Data for more countries will be available next year. Maps now supports Waze-like and Google Street View-like functionality. Strong emphasis on respecting privacy in terms of identity and visited places.

To better protect privacy, three new features: Allow just once, background tracking alerts, Wi-fi and bluetooth protections

There is now a "Sign In With Apple" option for sites that exhibit login options such as "sign in with Google" or "sign in with Facebook". Does not collect any information. In addition, for situations where one needs to provide an email address, Apple can create a random email address aimed at hiding the the actual email address of the user. Works with Android and Windows devices as well.

HomeKit Secure Video. Will enable security cameras to upload video footage to iCloud in a secure way. Also, HomeKit-enabled browsers. 

The Messages app will now support sharing of user names and images, memoji, and animoji. High level of customization for the (ani)moji. In addition, Messages will iunclude memoji stickers. Integrates emoji with memoji on the same place. This can be integrated with other apps, such as WeChat.

Camera now includes multiple adjustments and filters for photos **and** videos. Videos can even be rotated. Camera will also use ML to remove duplicate and emphasize the "best shots" instead. This feature is called *Days*. *Months* instead organizes the photos as albums. These features aim to greatly improve the photo browsing experience. *Years* is similar. 

AirPods, HomePod, Siri: Siri can now read messages as soon as they arrive and responses can be sent immediately. It is also possible to share music via airpods. HomePod now supports Handoff. Siri can now play live radio from multiple services, such as IHeartRadio and TuneIn. iOS Shortcuts is now available by default in iOS. This apps supports users in creating multi-step instructions via Siri. Siri's reading capabilities have also been improved. It even supports parameterized, user-built Siri shortcuts. 

"Big changes coming to iPad this year": **iPadOS**. Supports pining widgets to the launch screen. Apps can be slid over the main app running on the screen, for example, messages can appear on the right hand side while one browsers the Web. iPadOS supports something similar to multiple windows. In fact, Expose is now part of the OS. Files supports column view, besides icon and list view. iCloud drive now supports folder sharing. iPad now also supports SD cards and flash drives. Desktop-browsing to the iPad: instead of seeing the mobile site, it will be possible to see the desktop version of the site. Safari will also include a download manager. The iPad version now includes a scroll indicator. Undos are now executed by a three-finger swipe and this finger is supported for every app, not just the Apple ones. They've also improved the Apple Pencil latency by means of software, bringing its latency down to 9ms (used to be 20ms). **PencilKit API for iPad!!!!!** 
*Since there's now both iOS and iPadOS, does that mean that the work required to build an app that runs on both will be significantly greater? In case not, what will be the relationship between **iOS** and MacOS apps?*

## MacOS and Macs

New Mac Pro. New display.

New MacOS: Catalina. Three new apps: Apple Music, Apple Podcasts, Apple TV. Apple Music synching features are now integrated with Finder. Apple now uses ML to analyze the spoken contents of podcasts and creates podcast indexes based on that. iPads can now be used as secondary screens for Macs. 

MacOS can now be entirely controlled by voice. This is also the case for iOS. It supports rich dictation and editing, comprehensive navigation, iOS attention awareness. 

FindMy is a new app based on FindMyiPhone. It works even when the device is offline. The Mac works as a beacon, relaying info about the computer to nearby Apple devices, which relay it to the network. This data is obviosuly encrypted. 

Project Catalyst: supports the migration of iPad apps to the Mac. Apparently, it is not very hard to use. The idea of having only one codebase for a project that runs on both Macs and iPads sounds really cool. 

**RealityKit**: native integration with ARKit and support for the construction and execution of elements in an AR environment. It is available for both Mac and iOS. Reality Kit is a "modern, high performance 3D engine designed from the ground up for AR". Works together with a tool called RealityComposer. The latter lays out AR experiences. Works in both the Mac and the iPad. 

ARKit now supports more sophisticated people occlusion, requiring less manual work. It also includes more sophisticated support for motion capture. 

450000 apps using Swift in the app store. 

New framework for building apps built from the ground up in Swift: **SwiftUI**. Unbelievably more compact approach for app construction. **This will change the Foundations course completely**!!!!!! Lots of code can be created by drag and drop. Apparently, the construction of a view does not require OOP anymore (they've created a view using a struct). Live editing for apps in execution **on the device**. Seems like a combination of playgrounds and actual projects in a completely different way. **SwiftUI will be available across all the Apple platforms. That's the missing link!**

All the platforms will be available as a beta today.

 
# Platforms State of the Union

*This keynote basically presents the development parts of the main keynote in a bit more detail.*

Next year, building apps that apply to different screen sizes will be an App Store requirement. 

SwiftUI supports the construction of UIs in a declarative manner. For example, when an image is created, it is not stored in a variable. The code simply stastes that there will be an image on the screen with specific characteristics. SwiftUI is built upon four principles: (i) Declarative; (ii) Automatic; (iii) Compositional; (iv) Consistent. Lots of stuff are built automaticaly. To what extent can we customize that? Even animations are automated. The way stuff is declared is weird. For example, if textfields have to appear within a Stack, the syntax looks like a trailing closure. Is that really the case or is it really new syntax? Very little mutable state in the framework. Most of the tine, it is not necessary to build and run the app explicitly. 

Xcode supports live programming for production, differently from what happens with playgrounds. 

Previews make it possible to view what an app will look like for multiple different modes of exhibition (including different pieces of data) at the same time! 

SwiftUI and Xcode also support playground-like documentation that, in addition, is interactive. 

ABI Stability: reduces the size of an app by ensuring that there is only a single, consistent Swift runtime (this has been introduced prior). 

Xcode now supports Swift packages and Github is adding them to its package directory. In addition, Xcode allows the creation of multiple editors, however the users likes it. Renaming functionality has been improved: renaming a variable in one place affects multiple parts of the program. Version control is integrated live with the Xcode editor,showing, for example, how the code used to be prior to a modification. Xcode conditions supports simulation of multiple different practical situations such as different device temperatures. 

TestPlan  is a lot like using TravisCI for continuous integration based on multiple platforms. 

Xcode now supports something called **Code Review Mode**. 

Almost the entire iOS API has been ported to MacOS, except for some parts that are specific to mobile features. Making an app available for the Mac seems to be a matter of basically just clicking a button.

Operating system and user data will now be kept on separate volumes and the former will be a read-only volume. 

Notifications can now be sent directly to the watch. Also, three different approaches to stream audio directly to the watch: Network.framework, AVFoundation, forgot the last one. Finally, SwiftUI will also work for watchOS. More operations are now available for the construction of UIs for the watch.  Making a watch app independent from the phone is a matter of marking a checkbox. 

Something interesting from SwiftUI: Text($username, ...). What does this ``"$username"`` mean in the declaration of this textfield? Is it some kind of direct conneciton where the contents of the textfield are seamlessly stored in the username variable?

SF Symbols: icons that behave like a font and thus support resizing and different weights. 

UIWindowScene API for iPad. Window scene separates the app delegate and a scene delegate. This supports the creation multiple windows in the iPad screen. NSUserActivity is employed to help manage the state of these multiple windows. 

Voice Control is available for developers to test apps. One can try to use it to find accessibility problems, for example, a screen element that does not have a good label for voice control, like an image showing a name but without that same name being associated with it. In this scenario, trying to control the app using that name will fail. Accessibility APIs are available for all platforms. 

CreateML: a Mac app that supports the construction of machine learning models without the need to actually write code for that. 

*Metal*: The iOS simulator now supports Metal as well. In addition, the Xcode now includes a Metal memory debugger. Metal is now organized around three families of GPUs: common features, Apple GPU features, and Mac GPU features. Metal now provides support for advanced numerical computation not necessarily associated with graphics. This is based on a C++ API. 

# Apple Design Awards

The winners were

- Flow by Moleskine
- Ordia
- The Gardens Between
- Alphalt 9: Legends
- Pixelmator Photo
- Eloh
- Butterfly iQ
- Thumper
- HomeCourt

